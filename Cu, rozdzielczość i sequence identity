import requests

def fetch_pdb_ids():
    """
    Fetches PDB identifiers for structures containing Cu²⁺ (copper ion) 
    and meeting resolution criteria (0.5-1.5 Å) from the RCSB PDB database.

    It sends a query to the RCSB PDB API and filters results based on:
    - Presence of Cu²⁺ ligand
    - Resolution range between 0.5 and 1.5 Å

    The results are saved to a file "pdb_ids.txt".

    Returns:
        list: A list of retrieved PDB identifiers.
    """
    search_url = "https://search.rcsb.org/rcsbsearch/v2/query"

    query = {
        "query": {
            "type": "group",
            "logical_operator": "and",
            "nodes": [
                {
                    "type": "terminal",
                    "service": "text_chem",
                    "parameters": {
                        "attribute": "rcsb_chem_comp_container_identifiers.comp_id",
                        "operator": "in",
                        "value": ["CU"]  
                    }
                },
                {
                    "type": "group",
                    "logical_operator": "or",
                    "nodes": [
                        {
                            "type": "terminal",
                            "service": "text",
                            "parameters": {
                                "attribute": "rcsb_entry_info.resolution_combined",
                                "operator": "range",
                                "value": {
                                    "from": 0.5,
                                    "to": 1.0,
                                    "include_lower": True,
                                    "include_upper": False
                                }
                            }
                        },
                        {
                            "type": "terminal",
                            "service": "text",
                            "parameters": {
                                "attribute": "rcsb_entry_info.resolution_combined",
                                "operator": "range",
                                "value": {
                                    "from": 1.0,
                                    "to": 1.5,
                                    "include_lower": True,
                                    "include_upper": False
                                }
                            }
                        }
                    ]
                }
            ]
        },
        "return_type": "entry",
        "request_options": {
            "paginate": {
                "start": 0,
                "rows": 1000  
            }
        }
    }

    response = requests.post(search_url, json=query, headers={"Content-Type": "application/json"})

    if response.status_code == 200:
        data = response.json()
        pdb_ids = [entry["identifier"] for entry in data["result_set"]]
        
        with open("pdb_ids.txt", "w") as f:
            f.write("\n".join(pdb_ids))

        print(f"Pobrano {len(pdb_ids)} PDB ID i zapisano do pdb_ids.txt")
        return pdb_ids
    else:
        print("Błąd w pobieraniu danych:", response.status_code, response.text)
        return []

def fetch_fasta_sequences(pdb_ids):
    """
    Fetches FASTA sequences for given PDB identifiers and saves them to a file.

    Args:
        pdb_ids (list): List of PDB identifiers.

    Returns:
        list: A list of retrieved FASTA sequences.
    """
    fasta_sequences = []
    
    for pdb_id in pdb_ids:
        url = f"https://www.rcsb.org/fasta/entry/{pdb_id}"
        response = requests.get(url)
        if response.status_code == 200:
            fasta_sequences.append(response.text)
    
    with open("sequences.fasta", "w") as f:
        f.writelines(fasta_sequences)
    
    print("Pobrano sekwencje FASTA")
    return fasta_sequences

# Example of usage
pdb_ids = fetch_pdb_ids()
pdb_ids = pdb_ids[:30]  #analysis for the first few proteins to chceck if everything works
print(pdb_ids)
fasta_sequences = fetch_fasta_sequences(pdb_ids)
print(fasta_sequences)




import time

def run_clustal_omega(fasta_sequences, email):
    """
    Sends FASTA sequences to Clustal Omega for multiple sequence alignment (MSA).

    Args:
        fasta_sequences (list): List of FASTA sequences.
        email (str): Email address required by the API.

    Returns:
        str: The MSA result in FASTA format, or None if an error occurs.
    """
    sequences_to_clustal = "\n".join(fasta_sequences)

    response = requests.post(
        "https://www.ebi.ac.uk/Tools/services/rest/clustalo/run",
        data={
            "email": email,
            "sequence": sequences_to_clustal
        }
    )

    job_id = response.text
    status = ""

    print(f"Clustal Omega job started, job ID: {job_id}")

    while status != "FINISHED":
        time.sleep(20)  
        response = requests.get(f"https://www.ebi.ac.uk/Tools/services/rest/clustalo/status/{job_id}")
        status = response.text.upper()
        print(f"Clustal Omega status: {status}")

    response = requests.get(f"https://www.ebi.ac.uk/Tools/services/rest/clustalo/result/{job_id}/fa")

    if response.status_code == 200:
        msa_data = response.text
        print("Clustal Omega completed successfully.")
        return msa_data
    else:
        print(f"Error retrieving Clustal Omega results: {response.status_code}")
        return None



def run_mview(msa_data, email):
    """
    Sends the MSA result from Clustal Omega to MView for visualization.

    Args:
        msa_data (str): MSA result in FASTA format.
        email (str): Email address required by the API.

    Returns:
        str: The MView result in PIM format, or None if an error occurs.
    """
    response = requests.post(
        "https://www.ebi.ac.uk/Tools/services/rest/mview/run",
        data={
            "email": email,
            "sequence": msa_data
        }
    )

    job_id = response.text
    status = ""

    print(f"MView job started, job ID: {job_id}")

    while status != "FINISHED":
        time.sleep(20)
        response = requests.get(f"https://www.ebi.ac.uk/Tools/services/rest/mview/status/{job_id}")
        status = response.text.upper()
        print(f"MView status: {status}")

    response = requests.get(f"https://www.ebi.ac.uk/Tools/services/rest/mview/result/{job_id}/pim")

    if response.status_code == 200:
        mview_result = response.text
        print("MView completed successfully.")
        return mview_result
    else:
        print(f"Error retrieving MView results: {response.status_code}")
        return None

# Example usage
email = "a.filipiak@studms.ug.edu.pl"

msa_result = run_clustal_omega(fasta_sequences, email)

if msa_result:
    mview_result = run_mview(msa_result, email)
    print(mview_result)




import numpy as np

def parse_mview_output(output):
    """
    Parses the MView output into a NumPy matrix and replaces NaN values with infinity.

    Args:
        output (str): The MView result as a text string.

    Returns:
        np.ndarray: A NumPy array representing the identity matrix with NaN replaced by np.inf.
    """
    lines = output.strip().split("\n")
    matrix_data = []

    for line in lines:
        if line.startswith("Percent") or line.startswith("#"):
            continue
        
        parts = line.split()[2:]  # Keep only numerical values

        if parts:  # Ensures there is at least one value before converting
            matrix_data.append([float(x) for x in parts])
    
    matrix = np.array(matrix_data)

    # Replace NaN with infinity
    matrix[np.isnan(matrix)] = np.inf

    return matrix

identity_matrix = parse_mview_output(mview_result)

print(identity_matrix)



def find_low_similarity_pairs(matrix, pdb_ids, threshold=30):
    """
    Identifies protein pairs with sequence similarity below a given threshold.

    This function analyzes a similarity matrix and groups proteins that have a 
    similarity score below the specified threshold.

    Args:
        matrix (numpy.ndarray): A square matrix containing pairwise similarity scores.
        pdb_ids (list): A list of protein pdb identifiers corresponding to the matrix rows/columns.
        threshold (float, optional): The similarity percentage threshold. Pairs below this value are grouped. Default is 30.

    Returns:
        list: A list of lists, where each sublist contains a protein ID followed by 
              IDs of proteins with similarity below the threshold.
    """
    protein_groups = []
    for row_idx, row in enumerate(matrix):
        low_similarity_proteins = [
            pdb_ids[col_idx]
            for col_idx, value in enumerate(row)
            if col_idx != row_idx and value < threshold
        ]
        protein_groups.append([pdb_ids[row_idx]] + low_similarity_proteins)
    return protein_groups

protein_groups = find_low_similarity_pairs(identity_matrix, pdb_ids)
for entry in protein_groups:
    print(entry)


def filter_proteins(identity_matrix, protein_groups, pdb_ids):   #To jeszcze do doszlifowania!
    """
    Filters protein groups based on pairwise sequence identity.

    This function takes a matrix of sequence identities and removes proteins from groups 
    if they have more than 30% identity with any other protein in the same group.

    Args:
        identity_matrix (np.ndarray): A square matrix where each element (i, j) represents 
                                      the sequence identity percentage between protein i and j.
        protein_groups (list of list of str): A list of protein groups, where each group 
                                              is a list of protein pdb IDs.
        pdb_ids (list of str): A list of all protein pdb IDs corresponding to the indices in 
                                   the identity matrix.

    Returns:
        list of list of str: A filtered list of protein groups, where highly similar proteins 
                             (identity > 30%) have been removed.
    """
    protein_index = {protein: idx for idx, protein in enumerate(pdb_ids)}  #{pdb_id:index_in_matrix}
    
    filtered_groups = []
    
    for group in protein_groups:
        filtered_group = []
        
        for i, protein in enumerate(group):
            if protein not in protein_index:
                continue
            keep = True   #protein stays in the group
            
            for j in range(i + 1, len(group)):
                other_protein = group[j]
                
                if other_protein not in protein_index:
                    continue
                
                idx1, idx2 = protein_index[protein], protein_index[other_protein]
                identity = identity_matrix[idx1][idx2]
                
                if identity > 30:
                    keep = False   #protein bye bye
                    break
            
            if keep:
                filtered_group.append(protein)
        
        filtered_groups.append(filtered_group)
    
    return filtered_groups

filtered_groups = filter_proteins(identity_matrix, protein_groups, pdb_ids)
print(filtered_groups)
